{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKpgDxdjkn8l"
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "Congrats, you finished the part on the data preparation, and we can now move on to the more exciting part of using RNNs/LSTMs to process sequential data. But be careful, even if the previous notebook might seem a little bit boring, it is of great importance. Since we switched to text data in this homework, make sure you have a good understanding of how the data has been prepared.\n",
    "\n",
    "For the last Deep Learning homework, we want to make use of Recurrent Neural Networks (RNNs) to process sequential data. We will stick with the same dataset we have been looking at in the previous notebook, namely the [IMDb](https://ai.stanford.edu/~amaas/data/sentiment/) sentiment analysis dataset that contains positive and negative movie reviews.\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1WEg6_Y2cFMu163QHIXpRmbNT0rp80hEQ)\n",
    "\n",
    "\n",
    "Sentiment analysis is the task of predicting the sentiment of a text. In this notebook, you will train a network to process reviews from the dataset and evaluate whether it has been a positive or a negative review. Below are two examples:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1vOxwWdm3aB1k0SiWuMktX_cLRnTuWbOA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvqWkZtHkn8n"
   },
   "source": [
    "## (Optional) Mount folder in Colab\n",
    "\n",
    "Uncomment the following cell to mount your gdrive if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nYE9MGZDkn8o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\nimport os\\n\\ngdrive_path='/content/gdrive/MyDrive/DL_homeworks/homework_10'\\n\\n# This will mount your google drive under 'MyDrive'\\ndrive.mount('/content/gdrive', force_remount=True)\\n# In order to access the files in this notebook we have to navigate to the correct folder\\nos.chdir(gdrive_path)\\n# Check manually if all files are present\\nprint(sorted(os.listdir()))\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the following lines if you want to use Google Colab\n",
    "# We presume you created a folder \"DL_homeworks\" within your main drive folder, and put the homework there.\n",
    "# NOTE: terminate all other colab sessions that use GPU!\n",
    "# NOTE 2: Make sure the correct homework folder (e.g homework_10) is given.\n",
    "\n",
    "\"\"\"\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "gdrive_path='/content/gdrive/MyDrive/DL_homeworks/homework_10'\n",
    "\n",
    "# This will mount your google drive under 'MyDrive'\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "# In order to access the files in this notebook we have to navigate to the correct folder\n",
    "os.chdir(gdrive_path)\n",
    "# Check manually if all files are present\n",
    "print(sorted(os.listdir()))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5eMPzqNlkn8q"
   },
   "source": [
    "### Set up PyTorch environment in colab\n",
    "- (OPTIONAL) Enable GPU via Runtime --> Change runtime type --> GPU\n",
    "- Uncomment the following cell if you are using the notebook in google colab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG30U-Opkn8r"
   },
   "source": [
    "# 0. Setup\n",
    "\n",
    "As always, we first import some packages to setup the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nleTWnCVkn8r"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from exercise_code.rnn.sentiment_dataset import (\n",
    "    download_data,\n",
    "    load_sentiment_data,\n",
    "    load_vocab,\n",
    "    SentimentDataset,\n",
    "    collate\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gi1hVbHukn8s"
   },
   "source": [
    "# 1. Loading Data\n",
    "\n",
    "As we have learned from the notebook 1, this time we not only load the raw data, but also have the corresponding vocabulary. Let us load the data that we prepared for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8PNyA3oDkn8s"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples: 9154\n",
      "number of validation samples: 3133\n",
      "number of test samples: 3083\n"
     ]
    }
   ],
   "source": [
    "DL_homeworks_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "data_root = os.path.join(DL_homeworks_path, \"datasets\", \"SentimentData\")\n",
    "base_dir = download_data(data_root)\n",
    "vocab = load_vocab(base_dir)\n",
    "train_data, val_data, test_data = load_sentiment_data(base_dir, vocab)\n",
    "\n",
    "print(\"number of training samples: {}\".format(len(train_data)))\n",
    "print(\"number of validation samples: {}\".format(len(val_data)))\n",
    "print(\"number of test samples: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umOyDlN_kn8t"
   },
   "source": [
    "## Dataset Samples\n",
    "\n",
    "Our raw data consists of tuples `(raw_text, token_list, token_indices, label)`. Let's sample some relatively short texts from our dataset to have a sense how it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JRaQ0iBYkn8t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      " I wouldn't rent this one even on dollar rental night.\n",
      "\n",
      "Tokens: \n",
      " ['i', 'wouldn', 't', 'rent', 'this', 'one', 'even', 'on', 'dollar', 'rental', 'night']\n",
      "\n",
      "Indices: \n",
      " [7, 555, 23, 414, 10, 27, 64, 25, 2506, 1292, 314]\n",
      "\n",
      "Label:\n",
      " 0\n",
      "\n",
      "\n",
      "Text: \n",
      " You'd better choose Paul Verhoeven's even if you have watched it.\n",
      "\n",
      "Tokens: \n",
      " ['you', 'd', 'better', 'choose', 'paul', 'verhoeven', 's', 'even', 'if', 'you', 'have', 'watched', 'it']\n",
      "\n",
      "Indices: \n",
      " [20, 232, 107, 1999, 855, 4624, 16, 64, 35, 20, 26, 214, 8]\n",
      "\n",
      "Label:\n",
      " 0\n",
      "\n",
      "\n",
      "Text: \n",
      " I don't know why I like this movie so well, but I never get tired of watching it.\n",
      "\n",
      "Tokens: \n",
      " ['i', 'don', 't', 'know', 'why', 'i', 'like', 'this', 'movie', 'so', 'well', 'but', 'i', 'never', 'get', 'tired', 'of', 'watching', 'it']\n",
      "\n",
      "Indices: \n",
      " [7, 74, 23, 126, 138, 7, 32, 10, 13, 34, 68, 17, 7, 115, 82, 1225, 5, 116, 8]\n",
      "\n",
      "Label:\n",
      " 1\n",
      "\n",
      "\n",
      "Text: \n",
      " This is the definitive movie version of Hamlet. Branagh cuts nothing, but there are no wasted moments.\n",
      "\n",
      "Tokens: \n",
      " ['this', 'is', 'the', 'definitive', 'movie', 'version', 'of', 'hamlet', 'branagh', 'cuts', 'nothing', 'but', 'there', 'are', 'no', 'wasted', 'moments']\n",
      "\n",
      "Indices: \n",
      " [10, 9, 2, 1, 13, 304, 5, 2974, 2206, 2865, 151, 17, 44, 28, 62, 628, 385]\n",
      "\n",
      "Label:\n",
      " 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_data0 = [datum for datum in train_data if len(datum[1]) < 20 and datum[-1] == 0] # negative\n",
    "sample_data1 = [datum for datum in train_data if len(datum[1]) < 20 and datum[-1] == 1] # positive\n",
    "\n",
    "# we sample 2 tuples each from positive set and negative set\n",
    "sample_data = random.sample(sample_data0, 2) + random.sample(sample_data1, 2)\n",
    "for text, tokens, indices, label in sample_data:\n",
    "    print('Text: \\n {}\\n'.format(text))\n",
    "    print('Tokens: \\n {}\\n'.format(tokens))\n",
    "    print('Indices: \\n {}\\n'.format(indices))\n",
    "    print('Label:\\n {}\\n'.format(label))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3f7gOUxkn8u"
   },
   "source": [
    "## Checking the Vocabulary\n",
    "\n",
    "In the previous notebook, we discussed the need of a vocabulary for mapping words to unique integer IDs. Instead of creating the vocabulary manually, we provide you with the vocabulary. Let's have a look at some samples from the vocabulary of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wzzMCPMCkn8u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 5002 \n",
      "\n",
      "  Sample words\n",
      "--------------------\n",
      " trail\n",
      " code\n",
      " sticks\n",
      " clue\n",
      " bone\n",
      " davies\n",
      " britney\n",
      " jack\n",
      " tell\n",
      " held\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size:', len(vocab), '\\n\\n  Sample words\\n{}'.format('-' * 20))\n",
    "sample_words = random.sample(list(vocab.keys()), 10)\n",
    "for word in sample_words:\n",
    "    print(' {}'.format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgESR2Pnkn8v"
   },
   "source": [
    "Also we saw that there are already indices in the raw data that we loaded. We can check if the indices in the vocabulary match the raw data using the last sentence in `sample_data`. Words that are not in the vocabulary are assigned to the symbol `<unk>`. The output of the following cell should be the same as the indices in the last example of our loaded raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "5wRT0X8qkn8v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: \n",
      " This is the definitive movie version of Hamlet. Branagh cuts nothing, but there are no wasted moments.\n",
      "\n",
      "Tokens: \n",
      " ['this', 'is', 'the', 'definitive', 'movie', 'version', 'of', 'hamlet', 'branagh', 'cuts', 'nothing', 'but', 'there', 'are', 'no', 'wasted', 'moments']\n",
      "\n",
      "Indices: \n",
      " [10, 9, 2, 1, 13, 304, 5, 2974, 2206, 2865, 151, 17, 44, 28, 62, 628, 385]\n",
      "\n",
      "Label:\n",
      " 1\n",
      "\n",
      "Indices drawn from vocabulary: \n",
      " [10, 9, 2, 1, 13, 304, 5, 2974, 2206, 2865, 151, 17, 44, 28, 62, 628, 385]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Last sample from above \n",
    "(text, tokens, indices, label) = sample_data[-1]\n",
    "print('Text: \\n {}\\n'.format(text))\n",
    "print('Tokens: \\n {}\\n'.format(tokens))\n",
    "print('Indices: \\n {}\\n'.format(indices))\n",
    "print('Label:\\n {}\\n'.format(label))\n",
    "\n",
    "# Compare with the vocabulary\n",
    "print('Indices drawn from vocabulary: \\n {}\\n'.format([vocab.get(x, vocab['<unk>']) for x in sample_data[-1][1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LlZWKwwxkn8v"
   },
   "source": [
    "## Wrapping to PyTorch Datasets\n",
    "\n",
    "Great, the raw data is loaded properly and the vocabulary is matching. Let us wrap our data in a PyTorch dataset. For more details, check out the previous notebook and the corresponding dataset class defined in `exercise_code/rnn/sentiment_dataset.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9c1ee3rzkn8w"
   },
   "outputs": [],
   "source": [
    "# Define a Dataset Class for train, val and test set\n",
    "train_dataset = SentimentDataset(train_data)\n",
    "val_dataset = SentimentDataset(val_data)\n",
    "test_dataset = SentimentDataset(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhH_Q-iykn8w"
   },
   "source": [
    "# 2. Creating a Sentiment Classifier\n",
    "\n",
    "After we have loaded the data, it is time to define a model and start training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSlb8ePakn8w"
   },
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "Since we just need to predict positive or negative, we can use `binary cross-entropy loss` to train our model. And accuracy can be used to assess our model's performance. We will use the following evaluation model to compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0RUFlpQFkn8x"
   },
   "outputs": [],
   "source": [
    "bce_loss = nn.BCELoss()\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_accuracy(model, data_loader):\n",
    "    corrects = 0\n",
    "    total = 0\n",
    "    device = next(model.parameters()).device\n",
    "    \n",
    "    for i, x in enumerate(data_loader):\n",
    "        input = x['data'].to(device)\n",
    "        lengths = x['lengths']\n",
    "        label = x['label'].to(device)\n",
    "        pred = model(input, lengths)\n",
    "        corrects += ((pred > 0.5) == label).sum().item()\n",
    "        total += label.numel()\n",
    "        \n",
    "        if i > 0  and i % 100 == 0:\n",
    "            print('Step {} / {}'.format(i, len(data_loader)))\n",
    "    \n",
    "    return corrects / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcJgB8ehkn8x"
   },
   "source": [
    "## Step 1: Design your own model\n",
    "\n",
    "In this part, you need to create a classifier using the Embedding layers you implemented in the first notebook and LSTM. For the LSTM, you may also use the PyTorch implementation.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3>Task: Implement a Classifier</h3>\n",
    "    \n",
    "   Go to <code>exercise_code/rnn/text_classifiers.py</code> and implement the <code>RNNClassifier</code>. In the skeleton code, we inherited <code>nn.Module</code>. You can also inherit <code>LightningModule</code> if you want to use PyTorch Lightning.\n",
    "</div>\n",
    "\n",
    "This file is mostly empty but contains the expected class name, and the methods that your model needs to implement (only `forward()` basically). \n",
    "The only rules your model design has to follow are:\n",
    "* Inherit from `torch.nn.Module` or `pytorch_lightning.LightningModule`\n",
    "* Perform the forward pass in `forward()`.\n",
    "* Have less than 2 million parameters\n",
    "* Have a model size of less than 50MB after saving\n",
    "\n",
    "After you finished, edit the below cell to make sure your implementation is correct. You should define the model yourself, which should be small enough (2 Mio. parameters) and have correct output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "9CI--iFxkn8y",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 1035777\n",
      "Your model is sufficiently small.\n",
      "All output tests are passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exercise_code.rnn.tests import classifier_test, parameter_test\n",
    "from exercise_code.rnn.text_classifiers import RNNClassifier\n",
    "\n",
    "model = None\n",
    "\n",
    "########################################################################\n",
    "# TODO - Create a Model                                               #\n",
    "########################################################################\n",
    "\n",
    "num_embeddings = len(vocab)\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "use_lstm = True\n",
    "\n",
    "model = RNNClassifier(num_embeddings, embedding_dim, hidden_size, use_lstm)\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################\n",
    "\n",
    "# Check whether your model is sufficiently small and have a correct output format\n",
    "parameter_test(model), classifier_test(model, len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3K8Ch-Pkn8y"
   },
   "source": [
    "## Step 2: Train your own model\n",
    "\n",
    "In this section, you need to train the classifier you created. Below, you can see some setup code we provided to you. Note the **collate function** used with the `DataLoader`. If you forgot why we need the collate function here, check this out in Notebook 1.\n",
    "\n",
    "You are free to change the below configs (e.g. batch size, device setting etc.) as you wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "41aBnDZokn8y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training configs\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('Using {}...\\n'.format(device))\n",
    "\n",
    "# Move model to the device we are using\n",
    "model = model.to(device)\n",
    "\n",
    "# To tackle with the exploding gradient problem, you may want to set gclip and use clip_grad_norm_\n",
    "# see the first notebook for the explanation\n",
    "gclip = None\n",
    "\n",
    "# Dataloaders, note the collate function\n",
    "train_loader = DataLoader(\n",
    "  train_dataset, batch_size=128, collate_fn=collate, drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "  val_dataset, batch_size=128, collate_fn=collate, drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Seh8oadHkn8y"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<h3>Task: Implement Training</h3>\n",
    "    <p>\n",
    "        In the below cell, you are expected to implement your training loop to train your model. You can use the training loader provided above for iterating over the data. If you want to evaluate your model periodically, you may use the validation loader provided above. You can use pure PyTorch or PyTorch Lightning. \n",
    "        \n",
    "Use `torch.nn.BCELoss` as loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/015 | Batch 000/071 | Loss: 0.6976\n",
      "Training Accuracy: 0.69% | Validation Accuracy: 0.69%\n",
      "Epoch: 002/015 | Batch 000/071 | Loss: 0.7016\n",
      "Training Accuracy: 0.80% | Validation Accuracy: 0.77%\n",
      "Epoch: 003/015 | Batch 000/071 | Loss: 0.5410\n",
      "Training Accuracy: 0.81% | Validation Accuracy: 0.76%\n",
      "Epoch: 004/015 | Batch 000/071 | Loss: 0.4623\n",
      "Training Accuracy: 0.88% | Validation Accuracy: 0.82%\n",
      "Epoch: 005/015 | Batch 000/071 | Loss: 0.3348\n",
      "Training Accuracy: 0.90% | Validation Accuracy: 0.83%\n",
      "Epoch: 006/015 | Batch 000/071 | Loss: 0.2987\n",
      "Training Accuracy: 0.90% | Validation Accuracy: 0.85%\n",
      "Epoch: 007/015 | Batch 000/071 | Loss: 0.2793\n",
      "Training Accuracy: 0.91% | Validation Accuracy: 0.85%\n",
      "Epoch: 008/015 | Batch 000/071 | Loss: 0.2123\n",
      "Training Accuracy: 0.95% | Validation Accuracy: 0.84%\n",
      "Epoch: 009/015 | Batch 000/071 | Loss: 0.1673\n",
      "Training Accuracy: 0.96% | Validation Accuracy: 0.85%\n",
      "Epoch: 010/015 | Batch 000/071 | Loss: 0.1423\n",
      "Training Accuracy: 0.97% | Validation Accuracy: 0.84%\n",
      "Epoch: 011/015 | Batch 000/071 | Loss: 0.1701\n",
      "Training Accuracy: 0.96% | Validation Accuracy: 0.85%\n",
      "Epoch: 012/015 | Batch 000/071 | Loss: 0.1219\n",
      "Training Accuracy: 0.97% | Validation Accuracy: 0.85%\n",
      "Epoch: 013/015 | Batch 000/071 | Loss: 0.1088\n",
      "Training Accuracy: 0.98% | Validation Accuracy: 0.85%\n",
      "Epoch: 014/015 | Batch 000/071 | Loss: 0.1052\n",
      "Training Accuracy: 0.98% | Validation Accuracy: 0.85%\n",
      "Epoch: 015/015 | Batch 000/071 | Loss: 0.1065\n",
      "Training Accuracy: 0.98% | Validation Accuracy: 0.85%\n",
      "FINISH.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "NUM_EPOCHS = 15\n",
    "\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader) * NUM_EPOCHS)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        \n",
    "        inputs = data[\"data\"]\n",
    "        target = data[\"label\"]\n",
    "        lengths = data[\"lengths\"]\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        target = target.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(inputs, lengths)             \n",
    "        loss = criterion(y_pred, target) \n",
    "        loss.backward()             \n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()  # Step the scheduler after each batch processed\n",
    "        \n",
    "        if not batch_idx % 71:\n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                  f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                  f'Loss: {loss:.4f}')\n",
    "            \n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc = compute_accuracy(model, train_loader)  \n",
    "        val_acc = compute_accuracy(model, val_loader)  \n",
    "        \n",
    "        print(f'Training Accuracy: {train_acc:.2f}% | Validation Accuracy: {val_acc:.2f}%')\n",
    "\n",
    "print('FINISH.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "EgitURwvkn8z",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type      | Params\n",
      "----------------------------------------\n",
      "0 | embedding | Embedding | 640 K \n",
      "1 | rnn       | LSTM      | 395 K \n",
      "2 | fc        | Linear    | 257   \n",
      "3 | sigmoid   | Sigmoid   | 0     \n",
      "----------------------------------------\n",
      "1.0 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 M     Total params\n",
      "4.143     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 150. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 147. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d828f7d2b48f43e19ef0e1e165c4e4ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 144. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 142. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 139. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 137. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 135. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 133. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 130. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 126. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 123. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 121. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 118. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 114. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 111. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 106. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 100. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 90. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 82. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 72. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 65. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 57. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 49. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/Users/tigrangaplanyan/anaconda3/envs/Homeworks/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 39. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#                     TODO - Train Your Model                          #\n",
    "########################################################################\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=10, gradient_clip_val=40)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "########################################################################\n",
    "#                           END OF YOUR CODE                           #\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e4EIdaOkn8z"
   },
   "source": [
    "## Testing the Model\n",
    "\n",
    "As you trained a model and improved it on the validation set, you can now test it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "X_TAr_5ikn8z",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100 / 386\n",
      "Step 200 / 386\n",
      "Step 300 / 386\n",
      "accuracy on test set: 0.8462536490431398\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(\n",
    "  test_dataset, batch_size=8, collate_fn=collate, drop_last=False\n",
    ")\n",
    "\n",
    "print(\"accuracy on test set: {}\".format(compute_accuracy(model, test_loader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9ucap_Nkn80"
   },
   "source": [
    "## Demo\n",
    "\n",
    "\n",
    "Now that you trained a sufficiently good sentiment classifier, run the below cell and type some text to see some predictions (type exit to quit the demo). Since we used a small data, don't expect too much.\n",
    "<div class=\"alert alert-warning\">\n",
    "<h3>Warning!</h3>\n",
    "    <p>\n",
    "        As there is a while True loop in the cell below, you can skip this one for now and run the cell under '3. Submission' first to save your model. \n",
    "   </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yyt5-mDbkn80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love you\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "indices should be either on cpu or on the same device as the indexed tensor (cpu)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     10\u001b[0m words \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[1;32m     11\u001b[0m     w2i\u001b[38;5;241m.\u001b[39mget(word, w2i[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m tokenize(text)\n\u001b[1;32m     13\u001b[0m ])\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# T x B\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     16\u001b[0m sent \u001b[38;5;241m=\u001b[39m pred \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment -> \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Confidence -> \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:(\u001b[39m\u001b[38;5;124m'\u001b[39m, pred \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m pred\n\u001b[1;32m     20\u001b[0m ))\n",
      "File \u001b[0;32m~/anaconda3/envs/Homeworks/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Homeworks/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/DL_homeworks/homework_10/exercise_code/rnn/text_classifiers.py:71\u001b[0m, in \u001b[0;36mRNNClassifier.forward\u001b[0;34m(self, sequence, lengths)\u001b[0m\n\u001b[1;32m     64\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# TODO: Apply the forward pass of your network                         #\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# hint: Don't forget to use pack_padded_sequence if lenghts is not None#\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# pack_padded_sequence should be applied to the embedding outputs      #\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m embedded_seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lengths \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     embedded_seq \u001b[38;5;241m=\u001b[39m pack_padded_sequence(embedded_seq, lengths\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/anaconda3/envs/Homeworks/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Homeworks/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Downloads/DL_homeworks/homework_10/exercise_code/rnn/rnn_nn.py:234\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# TODO: Select the indices in the inputs from the weight tensor        #\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# hint: It is very short                                               #\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m#                           END OF YOUR CODE                           #\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m########################################################################\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[0;31mRuntimeError\u001b[0m: indices should be either on cpu or on the same device as the indexed tensor (cpu)"
     ]
    }
   ],
   "source": [
    "from exercise_code.rnn.sentiment_dataset import tokenize\n",
    "\n",
    "text = ''\n",
    "w2i = vocab\n",
    "while True:\n",
    "    text = input()\n",
    "    if text == 'exit':\n",
    "        break\n",
    "\n",
    "    words = torch.tensor([\n",
    "        w2i.get(word, w2i['<unk>'])\n",
    "        for word in tokenize(text)\n",
    "    ]).long().to(device).view(-1, 1)  # T x B\n",
    "\n",
    "    pred = model(words).item()\n",
    "    sent = pred > 0.5\n",
    "    \n",
    "    print('Sentiment -> {}, Confidence -> {}'.format(\n",
    "        ':)' if sent else ':(', pred if sent else 1 - pred\n",
    "    ))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPBr1BnCkn80"
   },
   "source": [
    "# 3. Submission\n",
    "\n",
    "If you got sufficient performance on the test data, you are ready to save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5YYuqtBrkn80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Your model is saved to models/rnn_classifier.p successfully!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/rnn_classifier.p'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from exercise_code.util.save_model import save_model\n",
    "\n",
    "save_model(model, 'rnn_classifier.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TTdJ4uaWkn81"
   },
   "source": [
    "Congrats, you finished the last Deep Learning homework! One last time this semester, let's prepare the submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yzOcnFwwkn81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant folders: ['exercise_code', 'models']\n",
      "notebooks files: ['1_recurrent_neural_networks.ipynb', '3_sentiment_analysis.ipynb', '2_text_preprocessing_and_embedding.ipynb']\n",
      "Adding folder exercise_code\n",
      "Adding folder models\n",
      "Adding notebook 1_recurrent_neural_networks.ipynb\n",
      "Adding notebook 3_sentiment_analysis.ipynb\n",
      "Adding notebook 2_text_preprocessing_and_embedding.ipynb\n",
      "Zipping successful! Zip is stored under: /Users/tigrangaplanyan/Downloads/DL_homeworks/output/homework_10.zip\n"
     ]
    }
   ],
   "source": [
    "# Now zip the folder for upload\n",
    "from exercise_code.util.submit import submit_exercise\n",
    "\n",
    "submit_exercise('../output/homework_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ydzdxZxakn81"
   },
   "source": [
    "# 4. Submission Goals\n",
    "\n",
    "- Goal: Implement and train a recurrent neural network for sentiment analysis.\n",
    "- Passing Criteria: Reach **Accuracy >= 83%** on the test dataset.\n",
    "\n",
    "- Submission deadline: __Sunday December 10, 2023 - 23:59__ \n",
    "- You can make **$\\infty$** submissions until the deadline. Your __best submission__ will be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
